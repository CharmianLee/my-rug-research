#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import os
import sys
import json
import subprocess
import argparse
import logging
import re
from pathlib import Path
from typing import Dict, List, Any, Optional

# ================= é…ç½® =================
# æŒ‡å®šä½¿ç”¨ nightly å·¥å…·é“¾è¿è¡Œè¦†ç›–ç‡ï¼Œä»¥æ”¯æŒ Branch Coverage
TOOLCHAIN = "+nightly" 
# å¿½ç•¥ RUG å¯èƒ½å¼•å…¥çš„éæ ¸å¿ƒæ–‡ä»¶æˆ–ä¾èµ–
IGNORE_REGEX = r"build\.rs|target/|vendor/|tests/"

logging.basicConfig(
    level=logging.INFO,
    format="[%(asctime)s] %(levelname)s: %(message)s",
    datefmt="%H:%M:%S"
)
logger = logging.getLogger("RugCov")

class RugCoverageRunner:
    def __init__(self, crate_path: Path, output_root: Path):
        self.crate_path = crate_path.resolve()
        self.crate_name = self.crate_path.name
        # æŠ¥å‘Šè¾“å‡ºç›®å½•ï¼šoutput_root/crate_name/
        self.report_dir = output_root.resolve() / self.crate_name
        self.json_path = self.report_dir / "coverage.json"
        self.summary_path = self.report_dir / "summary.md"
        self.test_stdout = ""
        self.test_stderr = ""

    def check_cargo_toml(self) -> bool:
        return (self.crate_path / "Cargo.toml").exists()

    def clean_previous_run(self):
        """æ¸…ç†æ—§çš„è¦†ç›–ç‡æ•°æ®ï¼Œé˜²æ­¢æ•°æ®æ±¡æŸ“"""
        logger.info(f"[{self.crate_name}] æ¸…ç†æ—§æ•°æ®...")
        subprocess.run(
            ["cargo", "llvm-cov", "clean", "--workspace"],
            cwd=self.crate_path,
            capture_output=True,
            check=False
        )

    def run_coverage(self) -> bool:
        """æ‰§è¡Œè¦†ç›–ç‡æµ‹è¯• (ä»…ç”Ÿæˆ Profile å’Œ JSONï¼Œä¸ç”Ÿæˆ HTML)"""
        logger.info(f"[{self.crate_name}] å¼€å§‹è¿è¡Œè¦†ç›–ç‡æµ‹è¯• (Branch Coverage Enabled)...")
        self.report_dir.mkdir(parents=True, exist_ok=True)

        # 1. è¿è¡Œæµ‹è¯•ï¼Œç”Ÿæˆ .profraw æ•°æ®
        # ç§»é™¤äº† --html å’Œ --output-dirï¼Œä»…è¿è¡Œæµ‹è¯•å¹¶è®°å½•è¦†ç›–ç‡
        cmd_test = [
            "cargo", TOOLCHAIN, "llvm-cov", "test",
            "--branch",
            "--workspace",
            "--ignore-filename-regex", IGNORE_REGEX,
            "--ignore-run-fail"
        ]

        # 2. ç”Ÿæˆ JSON æŠ¥å‘Š (åŸºäºä¸Šä¸€æ­¥ç”Ÿæˆçš„ profile)
        cmd_report = [
            "cargo", TOOLCHAIN, "llvm-cov", "report",
            "--json",
            "--output-path", str(self.json_path),
            "--ignore-filename-regex", IGNORE_REGEX
        ]

        try:
            env = os.environ.copy()
            # æ˜¾å¼å¼€å¯ instrument-coverageï¼Œç¡®ä¿ M4/Nightly å…¼å®¹æ€§
            env["RUSTFLAGS"] = "-C instrument-coverage" 
            
            # Step 1: Run Tests
            logger.info(f"[{self.crate_name}] Running tests (collecting profiles)...")
            result_test = subprocess.run(
                cmd_test,
                cwd=self.crate_path,
                env=env,
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
                text=True
            )
            
            # ä¿å­˜è¾“å‡ºä¾›åç»­åˆ†æ
            self.test_stdout = result_test.stdout
            self.test_stderr = result_test.stderr

            if result_test.returncode != 0:
                # å³ä½¿å¤±è´¥ï¼Œåªè¦ä¸æ˜¯ä¸¥é‡é”™è¯¯å¯¼è‡´æ— æ³•ç”Ÿæˆ profileï¼Œæˆ‘ä»¬éƒ½ç»§ç»­
                # ä½†å¦‚æœ stderr åŒ…å« "compilation failed" æˆ–è€…ç±»ä¼¼çš„ä¸¥é‡é”™è¯¯ï¼Œå¯èƒ½å°±æ²¡æœ‰ profile
                logger.warning(f"[{self.crate_name}] æµ‹è¯•è¿è¡ŒåŒ…å«å¤±è´¥ (Exit Code: {result_test.returncode})")
                # ä»…æ‰“å°æœ€åå‡ è¡Œä¾›è°ƒè¯•ï¼Œè¯¦ç»†ä¿¡æ¯ä¼šåœ¨æŠ¥å‘Šä¸­å±•ç¤º
                stderr_tail = '\n'.join(result_test.stderr.splitlines()[-5:])
                logger.warning(f"Stderr tail:\n{stderr_tail}")
                # return False # ä¸ç›´æ¥è¿”å› Falseï¼Œå°è¯•ç”ŸæˆæŠ¥å‘Š

            # Step 2: Generate JSON Report
            logger.info(f"[{self.crate_name}] Exporting coverage data to JSON...")
            result_report = subprocess.run(
                cmd_report,
                cwd=self.crate_path,
                env=env,
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
                text=True
            )

            if result_report.returncode != 0:
                logger.error(f"[{self.crate_name}] JSON æŠ¥å‘Šå¯¼å‡ºå¤±è´¥")
                stderr_tail = '\n'.join(result_report.stderr.splitlines()[-10:])
                logger.error(f"Stderr tail:\n{stderr_tail}")
                return False
            
            logger.info(f"[{self.crate_name}] JSON æ•°æ®å·²ç”Ÿæˆã€‚")
            return True

        except Exception as e:
            logger.error(f"è¿è¡Œå¼‚å¸¸: {e}")
            return False

    def _safe_div(self, n: int, d: int) -> float:
        return (n / d * 100.0) if d > 0 else 0.0

    def parse_metrics(self) -> Dict[str, Any]:
        """è§£æ JSON æå–æ›´ä¸°å¯Œçš„å…³é”®æŒ‡æ ‡"""
        if not self.json_path.exists():
            return {}

        try:
            with open(self.json_path, 'r') as f:
                data = json.load(f)
            
            if not data.get("data"):
                return {}
            
            # llvm-cov export json é€šå¸¸åœ¨ data[0]
            export_data = data["data"][0]
            files_data = export_data.get("files", [])
            
            # æ€»ä½“ç»Ÿè®¡ç´¯åŠ å™¨
            totals = {
                "lines": {"total": 0, "covered": 0},
                "branches": {"total": 0, "covered": 0},
                "functions": {"total": 0, "covered": 0},
                "regions": {"total": 0, "covered": 0}
            }
            
            file_details = []

            for file_obj in files_data:
                fname = file_obj.get("filename", "unknown")
                # è¿‡æ»¤é€»è¾‘
                if "src/" not in fname and "lib.rs" not in fname:
                    continue

                summary = file_obj.get("summary", {})
                
                # æå–å„ç»´åº¦æ•°æ®
                l_stats = summary.get("lines", {})
                b_stats = summary.get("branches", {})
                f_stats = summary.get("functions", {})
                r_stats = summary.get("regions", {})

                # å•æ–‡ä»¶ç»Ÿè®¡
                l_count, l_cov = l_stats.get("count", 0), l_stats.get("covered", 0)
                b_count, b_cov = b_stats.get("count", 0), b_stats.get("covered", 0)
                f_count, f_cov = f_stats.get("count", 0), f_stats.get("covered", 0)
                r_count, r_cov = r_stats.get("count", 0), r_stats.get("covered", 0)

                # ç´¯åŠ åˆ°æ€»ä½“
                totals["lines"]["total"] += l_count
                totals["lines"]["covered"] += l_cov
                totals["branches"]["total"] += b_count
                totals["branches"]["covered"] += b_cov
                totals["functions"]["total"] += f_count
                totals["functions"]["covered"] += f_cov
                totals["regions"]["total"] += r_count
                totals["regions"]["covered"] += r_cov

                # è®¡ç®—å•æ–‡ä»¶ç™¾åˆ†æ¯”
                l_pct = self._safe_div(l_cov, l_count)
                b_pct = self._safe_div(b_cov, b_count)
                f_pct = self._safe_div(f_cov, f_count)

                # è®¡ç®—ä¸€ä¸ªç®€å•çš„â€œå…³æ³¨åº¦åˆ†æ•°â€ï¼šåˆ†æ”¯è¦†ç›–ç‡è¶Šä½ä¸”è¡Œæ•°è¶Šå¤šï¼Œåˆ†æ•°è¶Šé«˜ï¼ˆè¶Šéœ€è¦å…³æ³¨ï¼‰
                # ä»…å½“åˆ†æ”¯æ€»æ•° > 0 æ—¶è®¡ç®—é£é™©ï¼Œé˜²æ­¢ç©ºæ–‡ä»¶å¹²æ‰°
                risk_score = (100 - b_pct) * (l_count / 100.0) if b_count > 0 else 0

                file_details.append({
                    "file": fname,
                    "metrics": {
                        "line": {"pct": l_pct, "cov": l_cov, "total": l_count},
                        "branch": {"pct": b_pct, "cov": b_cov, "total": b_count},
                        "function": {"pct": f_pct, "cov": f_cov, "total": f_count}
                    },
                    "risk_score": risk_score
                })

            # è®¡ç®—æ€»ä½“ç™¾åˆ†æ¯”
            overall = {}
            for key in totals:
                overall[key] = {
                    "pct": self._safe_div(totals[key]["covered"], totals[key]["total"]),
                    "stats": f"{totals[key]['covered']}/{totals[key]['total']}"
                }

            return {
                "overall": overall,
                "details": file_details
            }

        except Exception as e:
            logger.error(f"JSON è§£æå¤±è´¥: {e}")
            return {}

    def _get_status_icon(self, pct: float) -> str:
        """æ ¹æ®è¦†ç›–ç‡è¿”å›çŠ¶æ€å›¾æ ‡"""
        if pct >= 90: return "ğŸŸ¢ ä¼˜ç§€"
        if pct >= 75: return "ğŸŸ¡ è‰¯å¥½"
        if pct >= 50: return "ğŸŸ  è­¦å‘Š"
        return "ğŸ”´ å±é™©"

    def generate_markdown(self, metrics: Dict[str, Any]):
        """ç”Ÿæˆè¯¦ç»†çš„ Markdown æŠ¥å‘Š"""
        if not metrics:
            return

        ov = metrics["overall"]
        details = metrics["details"]
        test_results = self.analyze_test_results()

        with open(self.summary_path, 'w', encoding='utf-8') as f:
            f.write(f"# RUG æ·±åº¦è¦†ç›–ç‡æŠ¥å‘Š: `{self.crate_name}`\n\n")
            f.write(f"> **æ£€æµ‹æ—¶é—´**: {os.popen('date').read().strip()} | **æ¶æ„**: Apple Silicon M4\n\n")
            
            # 0. æµ‹è¯•æ‰§è¡Œç»“æœ (Test Execution)
            f.write("## 0. æµ‹è¯•æ‰§è¡Œç»“æœ (Test Execution)\n\n")
            status_icon = "ğŸŸ¢" if test_results["failed"] == 0 and test_results["total"] > 0 else "ğŸ”´"
            if test_results["total"] == 0: status_icon = "âšª"
            
            f.write(f"**çŠ¶æ€**: {status_icon} {test_results.get('status', 'Unknown')}\n\n")
            f.write(f"- **æ€»æµ‹è¯•æ•°**: {test_results['total']}\n")
            f.write(f"- **é€šè¿‡**: {test_results['passed']}\n")
            f.write(f"- **å¤±è´¥**: {test_results['failed']}\n")
            f.write(f"- **å¿½ç•¥**: {test_results['ignored']}\n\n")
            
            if test_results["failures_list"]:
                f.write("### âŒ å¤±è´¥æµ‹è¯•è¯¦æƒ…\n\n")
                for fail in test_results["failures_list"]:
                    f.write(f"#### `{fail['name']}`\n")
                    f.write(f"- **ä½ç½®**: `{fail['location']}`\n")
                    f.write(f"- **é”™è¯¯ä¿¡æ¯**:\n")
                    f.write(f"```text\n{fail['message']}\n```\n")
            
            # 1. æ ¸å¿ƒä»ªè¡¨ç›˜
            f.write("## 1. æ ¸å¿ƒæŒ‡æ ‡æ¦‚è§ˆ (Dashboard)\n\n")
            f.write("| ç»´åº¦ | è¦†ç›–ç‡ (%) | çŠ¶æ€ | å‘½ä¸­/æ€»æ•° | è¯´æ˜ |\n")
            f.write("| :--- | :---: | :---: | :---: | :--- |\n")
            
            # è¡Œè¦†ç›–
            l_pct = ov['lines']['pct']
            f.write(f"| **Lines (è¡Œ)** | **{l_pct:.2f}%** | {self._get_status_icon(l_pct)} | {ov['lines']['stats']} | åŸºç¡€å¯æ‰§è¡Œä»£ç è¦†ç›–æƒ…å†µ |\n")
            
            # åˆ†æ”¯è¦†ç›– (æœ€é‡è¦)
            b_pct = ov['branches']['pct']
            f.write(f"| **Branches (åˆ†æ”¯)** | **{b_pct:.2f}%** | {self._get_status_icon(b_pct)} | {ov['branches']['stats']} | **é€»è¾‘å®Œå¤‡æ€§æ ¸å¿ƒæŒ‡æ ‡** (if/match/loop) |\n")
            
            # å‡½æ•°è¦†ç›–
            f_pct = ov['functions']['pct']
            f.write(f"| **Functions (å‡½æ•°)** | **{f_pct:.2f}%** | {self._get_status_icon(f_pct)} | {ov['functions']['stats']} | æœªè¢«è°ƒç”¨çš„å‡½æ•°æ•°é‡ |\n\n")

            # 2. é‡ç‚¹å…³æ³¨æ–‡ä»¶ (Top 5 Risky)
            # æ’åºè§„åˆ™ï¼šé£é™©åˆ†å€’åºï¼ˆä¼˜å…ˆæ˜¾ç¤ºåˆ†æ”¯è¦†ç›–ä½ä¸”ä»£ç é‡å¤§çš„ï¼‰
            sorted_by_risk = sorted(details, key=lambda x: x['risk_score'], reverse=True)
            top_risky = [x for x in sorted_by_risk if x['metrics']['branch']['pct'] < 80 and x['metrics']['branch']['total'] > 0][:5]

            if top_risky:
                f.write("## 2. ğŸš¨ é‡ç‚¹å…³æ³¨æ–‡ä»¶ (Top Risky Files)\n")
                f.write("ä»¥ä¸‹æ–‡ä»¶ä»£ç é‡è¾ƒå¤§ä½†**åˆ†æ”¯è¦†ç›–ç‡è¾ƒä½**ï¼Œå»ºè®®ä¼˜å…ˆè¡¥å……æµ‹è¯•ç”¨ä¾‹ï¼š\n\n")
                f.write("| æ–‡ä»¶è·¯å¾„ | åˆ†æ”¯è¦†ç›–ç‡ | ç¼ºå¤±åˆ†æ”¯æ•° | ä»£ç è¡Œæ•° |\n")
                f.write("| :--- | :---: | :---: | :---: |\n")
                for item in top_risky:
                    display_name = item['file'].split(self.crate_name)[-1].lstrip(os.sep)
                    b_metric = item['metrics']['branch']
                    l_metric = item['metrics']['line']
                    missed_branches = b_metric['total'] - b_metric['cov']
                    f.write(f"| `{display_name}` | **{b_metric['pct']:.2f}%** | {missed_branches} | {l_metric['total']} |\n")
                f.write("\n")
            
            # 3. è¯¦ç»†æ–‡ä»¶åˆ—è¡¨
            f.write("## 3. æ‰€æœ‰æ–‡ä»¶è¯¦ç»†æ•°æ®\n\n")
            f.write("| æ–‡ä»¶å | è¡Œè¦†ç›–ç‡ (Line) | åˆ†æ”¯è¦†ç›–ç‡ (Branch) | å‡½æ•°è¦†ç›–ç‡ (Func) |\n")
            f.write("| :--- | :---: | :---: | :---: |\n")
            
            # æŒ‰åˆ†æ”¯è¦†ç›–ç‡å‡åºæ’åºæ˜¾ç¤ºæ‰€æœ‰æ–‡ä»¶
            sorted_files = sorted(details, key=lambda x: x['metrics']['branch']['pct'])
            
            for item in sorted_files:
                display_name = item['file'].split(self.crate_name)[-1].lstrip(os.sep)
                
                l_m = item['metrics']['line']
                b_m = item['metrics']['branch']
                f_m = item['metrics']['function']
                
                # ä½¿ç”¨ç®€å•çš„é¢œè‰²æ ‡è®°
                b_str = f"{b_m['pct']:.1f}%"
                if b_m['pct'] < 50 and b_m['total'] > 0:
                    b_str = f"ğŸ”´ {b_str}"
                elif b_m['pct'] < 80 and b_m['total'] > 0:
                    b_str = f"ğŸŸ  {b_str}"
                
                line_info = f"{l_m['pct']:.1f}% <br><sub style='color:gray'>({l_m['cov']}/{l_m['total']})</sub>"
                branch_info = f"{b_str} <br><sub style='color:gray'>({b_m['cov']}/{b_m['total']})</sub>"
                func_info = f"{f_m['pct']:.1f}% <br><sub style='color:gray'>({f_m['cov']}/{f_m['total']})</sub>"

                f.write(f"| `{display_name}` | {line_info} | {branch_info} | {func_info} |\n")

        logger.info(f"Markdown æŠ¥å‘Šå·²ç”Ÿæˆ: {self.summary_path}")

    def analyze_test_results(self) -> Dict[str, Any]:
        """è§£ææµ‹è¯•è¾“å‡ºï¼Œæå–å¤±è´¥ä¿¡æ¯å’Œç»Ÿè®¡"""
        results = {
            "total": 0,
            "passed": 0,
            "failed": 0,
            "ignored": 0,
            "failures_list": [],
            "summary_line": "æœªæ‰¾åˆ°æµ‹è¯•æ€»ç»“è¡Œ",
            "status": "Unknown"
        }
        
        # åˆå¹¶ stdout å’Œ stderr è¿›è¡Œåˆ†æï¼Œå› ä¸º cargo test çš„è¾“å‡ºå¯èƒ½æ··æ‚
        full_log = self.test_stdout + "\n" + self.test_stderr
        
        # 1. æå– Summary Line
        # test result: FAILED. 62 passed; 1 failed; 0 ignored; 0 measured; 0 filtered out; finished in 0.20s
        summary_match = re.search(r"test result: (.*?)\. (\d+) passed; (\d+) failed; (\d+) ignored;", full_log)
        if summary_match:
            results["status"] = summary_match.group(1)
            results["passed"] = int(summary_match.group(2))
            results["failed"] = int(summary_match.group(3))
            results["ignored"] = int(summary_match.group(4))
            results["total"] = results["passed"] + results["failed"] + results["ignored"]
            results["summary_line"] = summary_match.group(0)
        
        # 2. æå–è¯¦ç»†å¤±è´¥ä¿¡æ¯
        # æ¨¡å¼ï¼š
        # ---- test_name stdout ----
        # thread 'test_name' panicked at file:line:col:
        # message
        # ...
        
        # ç®€å•çš„åˆ‡åˆ†æ–¹æ³•ï¼šæŒ‰ "---- " åˆ‡åˆ†
        parts = full_log.split("---- ")
        for part in parts[1:]: # è·³è¿‡ç¬¬ä¸€ä¸ªï¼ˆé€šå¸¸æ˜¯å‰é¢çš„æ—¥å¿—ï¼‰
            # part æ ¼å¼ç±»ä¼¼: "duration::tests_rug_1::test_complex_combination stdout ----\n\nthread ... panicked at ..."
            lines = part.splitlines()
            if not lines: continue
            
            test_name_line = lines[0]
            if " stdout ----" not in test_name_line: continue
            
            test_name = test_name_line.replace(" stdout ----", "").strip()
            
            # å¯»æ‰¾ panic ä¿¡æ¯
            panic_info = "No panic message found"
            location = "Unknown location"
            
            content = "\n".join(lines[1:])
            
            # åŒ¹é… panic è¡Œ
            # æ ¼å¼1: thread '...' panicked at src/lib.rs:10:5:
            # æ ¼å¼2: thread '...' (1234) panicked at src/lib.rs:10:5:
            panic_match = re.search(r"thread '.*?'(?: \(.*?\))? panicked at (.*?:\d+:\d+):\n(.*)", content, re.DOTALL)
            if panic_match:
                location = panic_match.group(1)
                raw_msg = panic_match.group(2).strip()
                panic_info = "\n".join(raw_msg.splitlines()[:10])
            else:
                # å°è¯•åŒ¹é…å¦ä¸€ç§æ ¼å¼: panicked at 'message', file:line:col
                panic_match_2 = re.search(r"thread '.*?'(?: \(.*?\))? panicked at '(.*?)', (.*?:\d+:\d+)", content)
                if panic_match_2:
                    panic_info = panic_match_2.group(1)
                    location = panic_match_2.group(2)
                else:
                    # å°è¯•æ›´å®½æ³›çš„åŒ¹é…
                    panic_match_3 = re.search(r"panicked at (.*?:\d+:\d+):\n(.*)", content, re.DOTALL)
                    if panic_match_3:
                        location = panic_match_3.group(1)
                        raw_msg = panic_match_3.group(2).strip()
                        panic_info = "\n".join(raw_msg.splitlines()[:10])

            results["failures_list"].append({
                "name": test_name,
                "location": location,
                "message": panic_info
            })
            
        return results

def main():
    parser = argparse.ArgumentParser(description="RUG äº§ç‰©è¦†ç›–ç‡åˆ†æå·¥å…· (M4/Nightly) - Enhanced")
    parser.add_argument("input_path", type=Path, help="RUG è¾“å‡ºçš„å•ä¸ª Crate è·¯å¾„ï¼Œæˆ–è€…åŒ…å«å¤šä¸ª Crate çš„çˆ¶ç›®å½•")
    parser.add_argument("--output", type=Path, default=Path("coverage_reports"), help="æŠ¥å‘Šè¾“å‡ºç›®å½•")
    parser.add_argument("--batch", action="store_true", help="æ‰¹é‡æ¨¡å¼ï¼šè¾“å…¥è·¯å¾„æ˜¯åŒ…å«å¤šä¸ª crate çš„ç›®å½•")

    args = parser.parse_args()

    targets = []
    if args.batch:
        if not args.input_path.exists():
            logger.error("è¾“å…¥è·¯å¾„ä¸å­˜åœ¨")
            sys.exit(1)
        for item in args.input_path.iterdir():
            if item.is_dir() and (item / "Cargo.toml").exists():
                targets.append(item)
    else:
        targets.append(args.input_path)

    logger.info(f"æ£€æµ‹åˆ° {len(targets)} ä¸ªå¾…åˆ†æç›®æ ‡")

    for target in targets:
        runner = RugCoverageRunner(target, args.output)
        if not runner.check_cargo_toml():
            logger.warning(f"è·³è¿‡ {target}: æœªæ‰¾åˆ° Cargo.toml")
            continue
        
        runner.clean_previous_run()
        success = runner.run_coverage()
        
        if success:
            metrics = runner.parse_metrics()
            runner.generate_markdown(metrics)
        else:
            logger.error(f"{target.name} åˆ†æå¤±è´¥ï¼Œè¯·æ£€æŸ¥ä»£ç æ˜¯å¦å¯ç¼–è¯‘ã€‚")

if __name__ == "__main__":
    main()